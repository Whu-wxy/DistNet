// Configuration for the a machine comprehension model based on:
//   Seo, Min Joon et al. “Bidirectional Attention Flow for Machine Comprehension.”
//   ArXiv/1611.01603 (2016)
{
  "dataset_reader": {
    "type": "squad",
    "tokenizer": {
        "type": "word",
        "word_splitter":
            {
                "type": "spacy",
                "pos_tags": true,
                "ner": true
            }
        }
    },

    "token_indexers": {
      "tokens": {
        "type": "single_id",
        "lowercase_tokens": true
      },
      "token_characters": {
        "type": "characters",
        "character_tokenizer": {
          "byte_encoding": "utf-8",
          "start_tokens": [259],
          "end_tokens": [260]
        },
        "pos": {
                "type": "pos_tag"
            },
        "ner": {
                "type": "ner_tag"
        },
        "min_padding_length": 5
      }
    }
  },
   "vocabulary": {
        "min_count": {
            "token_characters": 200
        },
        "pretrained_files": {
            "tokens": "/glove/glove.840B.300d.lower.converted.zip"
        },
        "only_include_pretrained_words": true
    },
  "train_data_path": "/train-v1.1.json",
  "validation_data_path": "/dev-v1.1.json",
  "model": {
    "type": "bidaf",
    "text_field_embedder": {
        "token_embedders": {
            "tokens": {
                "type": "embedding",
                    "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip",
                    "embedding_dim": 300,
                    "trainable": false
            },
            "pos": {
                "type": "embedding",
                    "embedding_dim": 10,
                    "trainable": false
            },
            "ner": {
                "type": "embedding",
                    "embedding_dim": 10,
                    "trainable": false
            },
            "token_characters": {
                "type": "character_encoding",
                "embedding": {
                "embedding_dim": 64
                },
                "encoder": {
                "type": "cnn",
                        "embedding_dim": 64,
                        "num_filters": 200,
                        "ngram_filter_sizes": [
                            5
                        ]
                }
            }
        }
    },
    "num_highway_layers": 2,
    "phrase_layer": {
      "type": "lstm",
      "bidirectional": true,
      "input_size": 200,
      "hidden_size": 100,
      "num_layers": 1,
      "dropout": 0.2
    },
    "similarity_function": {
      "type": "linear",
      "combination": "x,y,x*y",
      "tensor_1_dim": 200,
      "tensor_2_dim": 200
    },
    "modeling_layer": {
      "type": "lstm",
      "bidirectional": true,
      "input_size": 800,
      "hidden_size": 100,
      "num_layers": 2,
      "dropout": 0.2
    },
    "span_end_encoder": {
      "type": "lstm",
      "bidirectional": true,
      "input_size": 1400,
      "hidden_size": 100,
      "num_layers": 1,
      "dropout": 0.2
    },
    "dropout": 0.2,
    "regularizer": [
            [
                ".*",
                {
                    "type": "l2",
                    "alpha": 1e-07
                }
            ]
        ]
  },
  "iterator": {
    "type": "bucket",
    "sorting_keys": [["passage", "num_tokens"], ["question", "num_tokens"]],
    "batch_size": 32
  },

  "trainer": {
    "num_epochs": 20,
    "grad_norm": 5.0,
    "patience": 3,
    "validation_metric": "+em",
    "cuda_device": 0,
    "learning_rate_scheduler":true,
    "learning_rate_scheduler": {
      "type": "reduce_on_plateau",
      "factor": 0.5,
      "mode": "max",
      "patience": 2
    },
    "optimizer": {
      "type": "adam",
      "betas": [0.9, 0.9]
    }
  }
}
